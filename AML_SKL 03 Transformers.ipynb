{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Machine Learning with Andreas Mueller \n",
    "\n",
    "# Transformers\n",
    "* Allow you to change representations of your data\n",
    "* Several transformers are often used for preprocessing \n",
    "* Split data into TEST and TRAIN sets\n",
    "\n",
    "### Unsupervised Transformations for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Training set\n",
    "* Each feature is a floating value, on varying scales: some close to zero, others in hundreds\n",
    "* Data is not in good format for many linear models, which assume data values on same scale\n",
    "* Scale the data very simply using mean and std dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.03961    0.         5.19    ...,   20.2      396.9        8.01   ]\n",
      " [   0.14476    0.        10.01    ...,   17.8      391.5       13.61   ]\n",
      " [   2.36862    0.        19.58    ...,   14.7      391.71      29.53   ]\n",
      " ..., \n",
      " [   0.5405    20.         3.97    ...,   13.       390.3        3.16   ]\n",
      " [   4.03841    0.        18.1     ...,   20.2      395.33      12.87   ]\n",
      " [   0.0795    60.         1.69    ...,   18.3      370.78       5.49   ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean : [   3.64755971   11.05145119   10.96757256    0.06596306    0.55184881\n",
      "    6.30326385   67.80448549    3.79751398    9.40105541  404.9525066\n",
      "   18.45382586  359.93559367   12.30408971] \n",
      "standard deviation : [   9.32755385   22.75394638    6.71348231    0.24821752    0.11150906\n",
      "    0.70102993   27.92897713    2.04025314    8.61841919  164.80258555\n",
      "    2.16664688   86.53846767    6.83761438] \n"
     ]
    }
   ],
   "source": [
    "print(\"mean : %s \" % X_train.mean(axis=0))\n",
    "print(\"standard deviation : %s \" % X_train.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data into scaled version using scaler.tranform\n",
    "* In contrast to supervised models where we predicted new outcomes\n",
    "* Here, we use transform to get a new view of the data\n",
    "* After transforming, data has mean of zero and standard deviation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean : [-0.  0.  0. -0. -0. -0.  0.  0. -0. -0.  0.  0. -0.] \n",
      "standard deviation : [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.] \n"
     ]
    }
   ],
   "source": [
    "print(\"mean : %s \" % X_scaled.mean(axis=0))\n",
    "print(\"standard deviation : %s \" % X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
